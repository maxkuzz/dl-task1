{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-31T07:41:53.478403Z",
     "start_time": "2025-10-31T07:41:49.576993Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/raw/training.1600000.processed.noemoticon.csv\",\n",
    "                 encoding=\"latin1\", header=None)\n",
    "\n",
    "df.columns = [\"label\", \"id\", \"date\", \"query\", \"user\", \"text\"]\n",
    "df = df[[\"text\", \"label\"]]  \n",
    "print(df.head())\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  label\n",
      "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...      0\n",
      "1  is upset that he can't update his Facebook by ...      0\n",
      "2  @Kenichan I dived many times for the ball. Man...      0\n",
      "3    my whole body feels itchy and like its on fire       0\n",
      "4  @nationwideclass no, it's not behaving at all....      0\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T07:41:53.501093Z",
     "start_time": "2025-10-31T07:41:53.478403Z"
    }
   },
   "cell_type": "code",
   "source": "df['label'].unique()",
   "id": "890eee5094c2553c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 4], dtype=int64)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T07:41:54.988996Z",
     "start_time": "2025-10-31T07:41:53.501093Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, remaining = train_test_split(df, test_size=0.36, random_state=42)\n",
    "val_df, test_df = train_test_split(remaining, test_size=0.4444, random_state=42)\n",
    "\n",
    "print(f\"Train: {len(train_df)/len(df):.2%}\")\n",
    "print(f\"Val:   {len(val_df)/len(df):.2%}\")\n",
    "print(f\"Test:  {len(test_df)/len(df):.2%}\")"
   ],
   "id": "854214f8596ff3d4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 64.00%\n",
      "Val:   20.00%\n",
      "Test:  16.00%\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T07:42:05.450811Z",
     "start_time": "2025-10-31T07:41:54.988996Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"stopwords\")\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r\"http\\S+|@\\w+|#\\w+|<.*?>|[^\\w\\s]\", \"\", str(text))\n",
    "    text = text.lower()\n",
    "    words = [w for w in text.split() if w not in stop_words]\n",
    "    return \" \".join(words)\n",
    "\n",
    "for part in [train_df, val_df, test_df]:\n",
    "    part[\"clean_text\"] = part[\"text\"].apply(clean_text)\n"
   ],
   "id": "f4ddfb83440c1741",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\maxim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T07:43:02.158385Z",
     "start_time": "2025-10-31T07:42:05.450811Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "for part in [train_df, val_df, test_df]:\n",
    "    part[\"tokens\"] = part[\"clean_text\"].apply(word_tokenize)\n"
   ],
   "id": "8b1418fd22ac0c33",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\maxim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T07:43:02.176471Z",
     "start_time": "2025-10-31T07:43:02.158385Z"
    }
   },
   "cell_type": "code",
   "source": "train_df.head()",
   "id": "cb0303bf7d1730ea",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                     text  label  \\\n",
       "657201  Can I get Wi-Fi for my iPhone on the plane tom...      0   \n",
       "195977  Muh bro is going to Busch Gardens....I'm not.....      0   \n",
       "839059  My friend matt is building a skateboard ramp.....      4   \n",
       "995544                loading boxcar racer in laptop  see      4   \n",
       "775883                 @shoe_8 i miss you too    text me?      0   \n",
       "\n",
       "                                               clean_text  \\\n",
       "657201  get wifi iphone plane tomorrow put airplane mo...   \n",
       "195977                      muh bro going busch gardensim   \n",
       "839059  friend matt building skateboard ramp perfect s...   \n",
       "995544                    loading boxcar racer laptop see   \n",
       "775883                                          miss text   \n",
       "\n",
       "                                                   tokens  \n",
       "657201  [get, wifi, iphone, plane, tomorrow, put, airp...  \n",
       "195977                [muh, bro, going, busch, gardensim]  \n",
       "839059  [friend, matt, building, skateboard, ramp, per...  \n",
       "995544              [loading, boxcar, racer, laptop, see]  \n",
       "775883                                       [miss, text]  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>657201</th>\n",
       "      <td>Can I get Wi-Fi for my iPhone on the plane tom...</td>\n",
       "      <td>0</td>\n",
       "      <td>get wifi iphone plane tomorrow put airplane mo...</td>\n",
       "      <td>[get, wifi, iphone, plane, tomorrow, put, airp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195977</th>\n",
       "      <td>Muh bro is going to Busch Gardens....I'm not.....</td>\n",
       "      <td>0</td>\n",
       "      <td>muh bro going busch gardensim</td>\n",
       "      <td>[muh, bro, going, busch, gardensim]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839059</th>\n",
       "      <td>My friend matt is building a skateboard ramp.....</td>\n",
       "      <td>4</td>\n",
       "      <td>friend matt building skateboard ramp perfect s...</td>\n",
       "      <td>[friend, matt, building, skateboard, ramp, per...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995544</th>\n",
       "      <td>loading boxcar racer in laptop  see</td>\n",
       "      <td>4</td>\n",
       "      <td>loading boxcar racer laptop see</td>\n",
       "      <td>[loading, boxcar, racer, laptop, see]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775883</th>\n",
       "      <td>@shoe_8 i miss you too    text me?</td>\n",
       "      <td>0</td>\n",
       "      <td>miss text</td>\n",
       "      <td>[miss, text]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T07:43:04.959952Z",
     "start_time": "2025-10-31T07:43:02.176471Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from collections import Counter\n",
    "\n",
    "counter = Counter([w for tokens in train_df[\"tokens\"] for w in tokens])\n",
    "vocab = {w: i+2 for i, (w, c) in enumerate(counter.items()) if c > 1}\n",
    "vocab[\"<pad>\"], vocab[\"<unk>\"] = 0, 1\n",
    "print(\"Vocab size:\", len(vocab))"
   ],
   "id": "416370ffd05cbd76",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 100943\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T07:43:09.284351Z",
     "start_time": "2025-10-31T07:43:04.959952Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def encode(tokens): \n",
    "    return [vocab.get(w, vocab[\"<unk>\"]) for w in tokens]\n",
    "\n",
    "for part in [train_df, val_df, test_df]:\n",
    "    part[\"encoded\"] = part[\"tokens\"].apply(encode)\n"
   ],
   "id": "63ef0323a1c855a5",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T07:44:19.294436Z",
     "start_time": "2025-10-31T07:44:19.280231Z"
    }
   },
   "cell_type": "code",
   "source": "test_df.head()",
   "id": "109dbf55c119f762",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                      text  label  \\\n",
       "1495891   my brother is back from uk for the summer!yeahy       4   \n",
       "245445   can't sleep yet  but trying to be happy.. plea...      0   \n",
       "164271   @grayguitar @andrewconnell I'm starting to fee...      0   \n",
       "1452627     @nessiecullenxD yah!! yah!! i love that, too.       4   \n",
       "998449   @jamesmills I'm gonna start calling you aidan ...      4   \n",
       "\n",
       "                                                clean_text  \\\n",
       "1495891                        brother back uk summeryeahy   \n",
       "245445   cant sleep yet trying happy please check wwwpt...   \n",
       "164271   im starting feel depressed hurricane talk im f...   \n",
       "1452627                                       yah yah love   \n",
       "998449   im gonna start calling aidan cant work technology   \n",
       "\n",
       "                                                    tokens  \\\n",
       "1495891                   [brother, back, uk, summeryeahy]   \n",
       "245445   [cant, sleep, yet, trying, happy, please, chec...   \n",
       "164271   [im, starting, feel, depressed, hurricane, tal...   \n",
       "1452627                                   [yah, yah, love]   \n",
       "998449   [im, gon, na, start, calling, aidan, cant, wor...   \n",
       "\n",
       "                                                   encoded  \n",
       "1495891                               [1770, 285, 1173, 1]  \n",
       "245445              [209, 382, 673, 685, 486, 10, 1449, 1]  \n",
       "164271   [54, 2130, 834, 4733, 17005, 871, 54, 1999, 8881]  \n",
       "1452627                                  [5446, 5446, 542]  \n",
       "998449     [54, 578, 76, 1036, 4905, 4185, 209, 227, 6944]  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1495891</th>\n",
       "      <td>my brother is back from uk for the summer!yeahy</td>\n",
       "      <td>4</td>\n",
       "      <td>brother back uk summeryeahy</td>\n",
       "      <td>[brother, back, uk, summeryeahy]</td>\n",
       "      <td>[1770, 285, 1173, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245445</th>\n",
       "      <td>can't sleep yet  but trying to be happy.. plea...</td>\n",
       "      <td>0</td>\n",
       "      <td>cant sleep yet trying happy please check wwwpt...</td>\n",
       "      <td>[cant, sleep, yet, trying, happy, please, chec...</td>\n",
       "      <td>[209, 382, 673, 685, 486, 10, 1449, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164271</th>\n",
       "      <td>@grayguitar @andrewconnell I'm starting to fee...</td>\n",
       "      <td>0</td>\n",
       "      <td>im starting feel depressed hurricane talk im f...</td>\n",
       "      <td>[im, starting, feel, depressed, hurricane, tal...</td>\n",
       "      <td>[54, 2130, 834, 4733, 17005, 871, 54, 1999, 8881]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452627</th>\n",
       "      <td>@nessiecullenxD yah!! yah!! i love that, too.</td>\n",
       "      <td>4</td>\n",
       "      <td>yah yah love</td>\n",
       "      <td>[yah, yah, love]</td>\n",
       "      <td>[5446, 5446, 542]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998449</th>\n",
       "      <td>@jamesmills I'm gonna start calling you aidan ...</td>\n",
       "      <td>4</td>\n",
       "      <td>im gonna start calling aidan cant work technology</td>\n",
       "      <td>[im, gon, na, start, calling, aidan, cant, wor...</td>\n",
       "      <td>[54, 578, 76, 1036, 4905, 4185, 209, 227, 6944]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T07:59:39.718300Z",
     "start_time": "2025-10-31T07:59:01.823802Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch\n",
    "\n",
    "MAX_LEN = 50  \n",
    "\n",
    "def pad_batch(sequences, max_len=MAX_LEN):\n",
    "    tensor_seqs = [torch.tensor(seq[:max_len]) for seq in sequences]\n",
    "    return pad_sequence(tensor_seqs, batch_first=True, padding_value=0)\n",
    "\n",
    "train_padded = pad_batch(train_df[\"encoded\"])\n",
    "val_padded   = pad_batch(val_df[\"encoded\"])\n",
    "test_padded  = pad_batch(test_df[\"encoded\"])\n"
   ],
   "id": "9815528f58f1fa35",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T08:00:02.909675Z",
     "start_time": "2025-10-31T08:00:02.899231Z"
    }
   },
   "cell_type": "code",
   "source": "print(train_padded)",
   "id": "3d5f28eaee4dcc0d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   2,    3,    4,  ...,    0,    0,    0],\n",
      "        [  12,   13,   14,  ...,    0,    0,    0],\n",
      "        [  17,   18,   19,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [1033, 1767,    1,  ...,    0,    0,    0],\n",
      "        [2216,  663,  389,  ...,    0,    0,    0],\n",
      "        [ 549, 2248,  272,  ...,    0,    0,    0]])\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T08:10:04.132650Z",
     "start_time": "2025-10-31T08:09:01.115137Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import gensim.downloader as api\n",
    "glove = api.load(\"glove-wiki-gigaword-100\")  # 100-мерные\n",
    "\n",
    "embedding_matrix = torch.zeros(len(vocab), 100)\n",
    "for i, word in enumerate(vocab.keys()):\n",
    "    if word in glove.key_to_index:\n",
    "        embedding_matrix[i] = torch.tensor(glove[word])\n",
    "    else:\n",
    "        embedding_matrix[i] = torch.randn(100)\n"
   ],
   "id": "efc5ca31a39fb280",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T09:24:12.645720Z",
     "start_time": "2025-11-04T09:24:12.629963Z"
    }
   },
   "cell_type": "code",
   "source": "embedding_matrix",
   "id": "bf04d14b0ff127a0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1443,  0.4395,  0.5832,  ...,  0.5013,  0.4954,  0.4992],\n",
       "        [-0.0191,  0.3890,  0.2648,  ..., -0.2924, -0.3516,  0.2613],\n",
       "        [-0.3609, -0.5975,  0.5235,  ...,  0.2213,  1.4631,  0.2227],\n",
       "        ...,\n",
       "        [-0.0554,  1.0538,  0.3631,  ...,  1.4923, -0.6138,  2.1924],\n",
       "        [ 0.5921, -0.7197,  1.0233,  ...,  0.0659,  0.5075, -0.5626],\n",
       "        [-0.2779,  0.1448, -0.2056,  ...,  1.1642,  1.0713, -0.2996]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
